{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "import models\n",
    "import random,time\n",
    "from time import sleep\n",
    "import copy \n",
    "import datetime\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from filelock import FileLock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_loader(batch_size,kwargs):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=True, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Pad(4),\n",
    "            transforms.RandomCrop(32),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    return train_loader\n",
    "\n",
    "def generate_test_loader(test_batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])),batch_size=test_batch_size, shuffle=True)\n",
    "    return test_loader\n",
    "\n",
    "def _get_params(model):\n",
    "    bns = {}\n",
    "    non_bns = {}\n",
    "    param_count = 0.\n",
    "    bn_param_count = 0.\n",
    "    for name,param in model.named_parameters():\n",
    "        param_count += len(param)\n",
    "        if 'bn' in name:\n",
    "            bns[name] = param\n",
    "            bn_param_count += len(param)\n",
    "        else:\n",
    "            non_bns[name] = param\n",
    "    print(\"bn params occupies: \",bn_param_count/param_count)\n",
    "    return bns,non_bns\n",
    "\n",
    "@ray.remote\n",
    "class ParameterServer():\n",
    "    def __init__(self,args,test_loader):\n",
    "        self.model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=args.depth)\n",
    "        self.stalness_table = [0] * args.num_workers\n",
    "        self.stalness_limit = args.stalness_limit \n",
    "        self.global_step = 0\n",
    "        self.lr = args.lr\n",
    "        self.args = args\n",
    "        self.eva_model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=args.depth)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                          lr=args.lr,\n",
    "                          momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "        self.test_loader = test_loader\n",
    "        self.model.cpu()\n",
    "        self.eva_model.cpu()\n",
    "        self.ps_writer = SummaryWriter(os.path.join(os.getcwd(),(args.tb_path+'/ps')))\n",
    "        self.save_path = args.save\n",
    "        self.num_workers = (int)(args.num_workers)\n",
    "        \n",
    "        # get point to all non_bns parameters\n",
    "        self.non_bns = [param.data for name,param in self.model.named_parameters() if 'bn' not in name]\n",
    "        self.bns = [param.data for name,param in self.model.named_parameters() if 'bn' in name]\n",
    "        self.bns_sync = [None] * args.num_workers\n",
    "        \n",
    "        if args.refine:\n",
    "            if os.path.isfile(args.refine):\n",
    "                print('found pruned ckpt')\n",
    "                checkpoint = torch.load(args.refine)\n",
    "                self.model = models.__dict__['resnet'](dataset='cifar10', depth=args.depth, cfg=checkpoint['cfg'])\n",
    "                \n",
    "                if args.resume:\n",
    "                    checkpoint = torch.load(args.resume)\n",
    "                    self.global_step = checkpoint['global_step']\n",
    "                    self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                    self.stalness_table = [self.global_step/args.num_workers] * args.num_workers\n",
    "                    \n",
    "                self.model.load_state_dict(checkpoint['state_dict'])\n",
    "                self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                          lr=args.lr,\n",
    "                          momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "\n",
    "        elif args.resume:\n",
    "            if os.path.isfile(args.resume):\n",
    "                print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "                checkpoint = torch.load(args.resume)\n",
    "                self.global_step = checkpoint['global_step']\n",
    "                self.model.load_state_dict(checkpoint['state_dict'])\n",
    "                self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                self.stalness_table = [self.global_step/args.num_workers] * args.num_workers\n",
    "                print(\"=> loaded checkpoint '{}' (global step: {})\".format(args.resume, checkpoint['global_step']))                \n",
    "                if 'epoch' in checkpoint: print(\"epoch: {}\".format(checkpoint['epoch']))\n",
    "            else:\n",
    "                print(\"=> no checkpoint found at '{}'\".format(args.resume))                    \n",
    "                \n",
    "    def apply_gradients(self, iter_diff, wk_idx, epoch):\n",
    "        if args.debug: print(\"applying gradients from the \",wk_idx, \" worker\")\n",
    "        \n",
    "        # updata all params\n",
    "        for idx, p in enumerate(self.model.parameters()):\n",
    "            p.data -= iter_diff[idx]\n",
    "\n",
    "#         if wk_idx == 0:\n",
    "#             # updata all params\n",
    "#             for idx, p in enumerate(self.model.parameters()):\n",
    "#                 p.data -= iter_diff[idx]\n",
    "#         else:\n",
    "#             # only update non_bns params\n",
    "#             for idx, tensor in enumerate(self.non_bns):\n",
    "#                 tensor -= iter_diff[idx]\n",
    "        \n",
    "#         # only update non_bns params\n",
    "#         for idx, tensor in enumerate(self.non_bns):\n",
    "#             tensor -= iter_diff[idx]\n",
    "        \n",
    "        self.stalness_table[wk_idx] += 1\n",
    "        self.global_step += 1\n",
    "        if args.debug: print(\"finished applying gradients from the \",wk_idx, \" worker\")\n",
    "        if self.global_step % 1000 == 0:\n",
    "#             print(\"global_step: \",self.global_step,\" and prepare evaluate\")\n",
    "#             self.evaluate()\n",
    "            self.save_ckpt({\n",
    "                'epoch':epoch,\n",
    "                'global_step':self.global_step,\n",
    "                'state_dict':self.model.state_dict(),\n",
    "                'optimizer':self.optimizer.state_dict()\n",
    "            },filepath=os.path.join(os.getcwd(),self.save_path))\n",
    "    \n",
    "    def apply_gradients_with_running_bn(self,iter_diff,wk_idx,epoch):\n",
    "        state = self.model.state_dict()\n",
    "        for idx, p in enumerate(state):\n",
    "            state[p] -= iter_diff[idx]\n",
    "            \n",
    "        self.stalness_table[wk_idx] += 1\n",
    "        self.global_step += 1\n",
    "        if args.debug: print(\"finished applying gradients from the \",wk_idx, \" worker\")\n",
    "        if self.global_step % 1000 == 0:\n",
    "            self.save_ckpt({\n",
    "                'epoch':epoch,\n",
    "                'global_step':self.global_step,\n",
    "                'state_dict':self.model.state_dict(),\n",
    "                'optimizer':self.optimizer.state_dict()\n",
    "            },filepath=os.path.join(os.getcwd(),self.save_path))\n",
    "        if self.global_step % (782 * 3) == 0:\n",
    "            print(\"global_step: \",self.global_step,\" and prepare evaluate\")\n",
    "            self.evaluate()\n",
    "\n",
    "    \n",
    "    def apply_gradients_non_bns(self,iter_diff,wk_idx,epoch):\n",
    "        for i in range(len(self.non_bns)):\n",
    "            self.non_bns[i] -= iter_diff[i]\n",
    "#         print(wk_idx,\"finished updating non bns on ps\")\n",
    "\n",
    "        \n",
    "    def apply_gradients_bns(self,iter_diff,wk_idx,epoch):\n",
    "        for idx, tensor in enumerate(self.bns):\n",
    "#             if idx == len(iter_diff) / 2:\n",
    "#                 print(wk_idx,\"is in the middle of updating bns on ps\")\n",
    "            tensor -= iter_diff[idx]\n",
    "#         print(wk_idx,\"finished updating non bns on ps\")\n",
    "#         self.stalness_table[wk_idx] += 1\n",
    "#         self.global_step += 1\n",
    "\n",
    "    def apply_gradients_partical_bns(self, iter_diff, wk_idx, epoch):\n",
    "        if wk_idx == 0 :\n",
    "            for i in range(0,(int)(len(self.bns)/self.num_workers)):\n",
    "                self.bns[i] -= iter_diff[i]\n",
    "        elif wk_idx == self.num_workers:\n",
    "            for i in range((int)(len(self.bns) * wk_idx / self.num_workers + 1) , len(self.bns)):\n",
    "                self.bns[i] -= iter_diff[i]\n",
    "        else:\n",
    "            for i in range((int)(len(self.bns) * wk_idx / self.num_workers + 1) , (int)(len(self.bns) * (wk_idx + 1) / self.num_workers)):\n",
    "                self.bns[i] -= iter_diff[i]\n",
    "        self.stalness_table[wk_idx] += 1\n",
    "        self.global_step += 1\n",
    "        if self.global_step % 1000 == 0:\n",
    "            self.save_ckpt({\n",
    "                'epoch':epoch,\n",
    "                'global_step':self.global_step,\n",
    "                'state_dict':self.model.state_dict(),\n",
    "                'optimizer':self.optimizer.state_dict()\n",
    "            },filepath=os.path.join(os.getcwd(),self.save_path))\n",
    "\n",
    "        \n",
    "    def pull_weights(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def pull_non_bn_weights(self):\n",
    "        self.non_bns = [param.data for name,param in self.model.named_parameters() if 'bn' not in name]\n",
    "        return copy.deepcopy(self.non_bns)\n",
    "    \n",
    "    def pull_bn_weights(self):\n",
    "        self.bns = [param.data for name,param in self.model.named_parameters() if 'bn' in name]\n",
    "        return copy.deepcopy(self.bns)\n",
    "    \n",
    "    def get_optim(self):\n",
    "        return self.optimizer\n",
    "    \n",
    "    def pull_optimizer_state(self):\n",
    "        return self.optimizer.state_dict()\n",
    "\n",
    "    def check_stalness(self,wk_idx):\n",
    "        min_iter = min(self.stalness_table)\n",
    "        return self.stalness_table[wk_idx] - min_iter < self.stalness_limit\n",
    "        \n",
    "    def get_stalness(self):\n",
    "        return min(self.stalness_table)\n",
    "    \n",
    "    def get_stalness_table(self):\n",
    "        return self.stalness_table\n",
    "    \n",
    "    def get_global_step(self):\n",
    "        return self.global_step\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def save_ckpt(self,state,filepath):\n",
    "        torch.save(state,os.path.join(filepath,'checkpoint.pth.tar'))\n",
    "    \n",
    "    def get_bns_ready(self):\n",
    "        return any(self.bns_sync) == False\n",
    "        \n",
    "    def aggregate_bns(self,wk_bns,worker_index):\n",
    "        self.bns_sync[worker_index] = wk_bns\n",
    "        if all(self.bns_sync):\n",
    "            for i in range(len(self.bns)):\n",
    "                tmp = copy.deepcopy(self.bns_sync[0][i])\n",
    "                for j in range(1, self.num_workers):\n",
    "                    tmp += self.bns_sync[j][i]\n",
    "                self.bns[i] = tmp / self.num_workers    \n",
    "            self.bns_sync = [None] * self.num_workers\n",
    "        return self.bns_sync\n",
    "    \n",
    "    def evaluate(self):\n",
    "        print(\"going to evaluate\")\n",
    "        test_loss = 0.\n",
    "        correct = 0.\n",
    "        print(\"pulled weights\")\n",
    "        self.eva_model= copy.deepcopy(self.model)\n",
    "        print(\"loaded weights\")\n",
    "        print(\"length of the test_loader dataset is : \",len(self.test_loader.dataset))\n",
    "        self.eva_model.eval()\n",
    "        count = 0\n",
    "        for data,target in self.test_loader:\n",
    "            count += 1\n",
    "            if count % 20 == 0: print(\"in eval, the batch is: \",count)\n",
    "            data, target = Variable(data,volatile=True),Variable(target)\n",
    "            output = self.eva_model(data)\n",
    "            batch_loss = F.cross_entropy(output, target, size_average=False).data\n",
    "            test_loss += batch_loss\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        len_testset = len(self.test_loader.dataset)\n",
    "        test_loss /= len_testset \n",
    "        accuracy = correct.float() / len_testset\n",
    "        # log \n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f})\\n'.format(\n",
    "        test_loss, correct, len_testset,accuracy))\n",
    "\n",
    "        self.ps_writer.add_scalar('Accuracy/eval', accuracy, self.global_step)\n",
    "        self.ps_writer.add_scalar('Loss/eval',test_loss , self.global_step)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def worker_task(args,ps,worker_index, train_loader):\n",
    "    # Initialize the model.\n",
    "#     if args.debug: print(worker_index, \" worker is going to sleep \",worker_index*5000)\n",
    "#     time.sleep(worker_index * 5000)\n",
    "    \n",
    "    model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=args.depth)\n",
    "    local_step = 0\n",
    "    \n",
    "    wk_non_bns = [param.data for name,param in model.named_parameters() if 'bn' not in name]\n",
    "    wk_bns = [param.data for name,param in model.named_parameters() if 'bn' in name]\n",
    "    \n",
    "    if args.cuda:\n",
    "        starttime = datetime.datetime.now()\n",
    "        model.cuda()\n",
    "        endtime = datetime.datetime.now()\n",
    "        time_cost = (endtime - starttime).seconds\n",
    "        if args.debug: print(\"move model to gpu takes: \", time_cost, \"seconds\")\n",
    "            \n",
    "    # all workers owns the same init values\n",
    "#     init_wei = ray.get(ps.pull_weights.remote())\n",
    "#     model.load_state_dict(init_wei)\n",
    "    \n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=args.lr,\n",
    "                      momentum=args.momentum,\n",
    "                      weight_decay=args.weight_decay)\n",
    "    \n",
    "            \n",
    "    if args.refine:\n",
    "        if os.path.isfile(args.refine):\n",
    "            print('found pruned ckpt')\n",
    "            checkpoint = torch.load(args.refine)\n",
    "            model = models.__dict__['resnet'](dataset='cifar10', depth=args.depth, cfg=checkpoint['cfg'])\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=args.lr,\n",
    "                      momentum=args.momentum,\n",
    "                      weight_decay=args.weight_decay)\n",
    "            if args.resume:\n",
    "                checkpoint = torch.load(args.resume)\n",
    "                model.load_state_dict(checkpoint['state_dict'])\n",
    "                local_step = int(checkpoint['global_step'] / args.num_workers)\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                print(\"worker #\",worker_index,\"resumes from local_step: \",local_step)\n",
    "                if 'epoch' in checkpoint:\n",
    "                    args.start_epoch = checkpoint['epoch']\n",
    "                    \n",
    "            \n",
    "    elif args.resume:\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        local_step = int(checkpoint['global_step'] / args.num_workers)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"worker #\",worker_index,\"resumes from local_step: \",local_step)\n",
    "        if 'epoch' in checkpoint:\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            \n",
    "    \n",
    "    wk_writer = SummaryWriter(os.path.join(os.getcwd(),args.tb_path,('wk_'+str(worker_index))))\n",
    "    print(\"worker #\",worker_index,\" is online\")\n",
    "    \n",
    "#     if local_step in [5500,7000]:\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         print(\"previous lr: \",param_group['lr'])\n",
    "#         param_group['lr'] = 0.001\n",
    "#         print(\"new lr: \",param_group['lr'])\n",
    "\n",
    "    \n",
    "    for epoch in range(args.start_epoch,args.epochs):\n",
    "        avg_loss = 0.\n",
    "        train_correct = 0.\n",
    "        for batch_idx,(data,target) in enumerate(train_loader):\n",
    "            if args.cuda:\n",
    "                starttime = datetime.datetime.now()\n",
    "                data,target = data.cuda(),target.cuda()\n",
    "                mid = datetime.datetime.now()\n",
    "                if args.debug: print(\"move data to gpu takes: \", (mid - starttime).seconds, \"seconds\")\n",
    "                model.cuda()\n",
    "                endtime = datetime.datetime.now()\n",
    "                time_cost = (endtime - starttime).seconds\n",
    "                if args.debug: print(\"move model to gpu takes: \", time_cost, \"seconds\")\n",
    "                \n",
    "            while(local_step - ray.get(ps.get_stalness.remote()) > args.stalness_limit):\n",
    "                sleep(1)\n",
    "            \n",
    "\n",
    "            # Get all weights from the parameter server.\n",
    "            if args.debug: print(\"the \",worker_index,\" pulls wei from ps.\")\n",
    "            init_wei = ray.get(ps.pull_weights.remote())\n",
    "            model.load_state_dict(init_wei)\n",
    "            model.cpu()\n",
    "#           # This doesn't contain BN running mean and var\n",
    "#             old_tensors = copy.deepcopy([p.data for p in model.parameters()]) \n",
    "\n",
    "            old_tensors = copy.deepcopy([param.data for name, param in model.state_dict().items()])\n",
    "\n",
    "            model.cuda()\n",
    "#             if args.debug: print(\"the \",worker_index,\" loaded the latest wei from ps.\")\n",
    "#             model.cpu()    \n",
    "#             wk_non_bns = [param.data for name,param in model.named_parameters() if 'bn' not in name]\n",
    "#             wk_bns = [param.data for name,param in model.named_parameters() if 'bn' in name]\n",
    "#             model.cuda()\n",
    "#             old_tensors_non_bns = copy.deepcopy(wk_non_bns)\n",
    "#             old_tensors_bns = copy.deepcopy(wk_bns)\n",
    "                \n",
    "#             # Get only non-bn weights from the parameter server.\n",
    "#             ps_non_bns = ray.get(ps.pull_non_bn_weights.remote())\n",
    "#             print(worker_index,\"pulled non bns from ps\")\n",
    "#             assert len(ps_non_bns) == len(wk_non_bns)\n",
    "#             for i in range(len(ps_non_bns)):\n",
    "#                 if i == len(ps_non_bns) / 2:\n",
    "#                     print(worker_index,\"is in the middle of updating non bns\")\n",
    "#                 wk_non_bns[i] = ps_non_bns[i]\n",
    "#             print(worker_index,\"updated non bns from ps and is going to pull bns \")\n",
    "            \n",
    "#             # Get only bn weights from the parameter server.\n",
    "#             ps_bns = ray.get(ps.pull_bn_weights.remote())\n",
    "#             print(worker_index,\"pulled bns from ps\")\n",
    "#             assert len(ps_bns) == len(wk_bns)\n",
    "#             for i in range(len(ps_bns)):\n",
    "#                 if i == len(ps_bns) / 2 :\n",
    "#                     print(worker_index, \"is in the middle of updating bns\")\n",
    "#                 wk_bns[i] = ps_bns[i]\n",
    "#             print(worker_index,\"updated bns from ps\")\n",
    "\n",
    "                \n",
    "            # Compute an update and push it to the parameter server.        \n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            if args.debug: print(worker_index,' is generating output')\n",
    "            output = model(data)\n",
    "            if args.debug: print(worker_index,' generated output done and going to calculate loss')\n",
    "            loss = F.cross_entropy(output,target)\n",
    "            avg_loss += loss\n",
    "            pred = output.data.max(1,keepdim=True)[1]\n",
    "            batch_correct = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            train_correct += batch_correct\n",
    "            if args.debug: print(worker_index,' calculated loss and going to bp')\n",
    "            loss.backward()\n",
    "            if args.debug: print(worker_index,' bp done')\n",
    "            \n",
    "            if(args.sr):\n",
    "                # additional subgradient descent on the sparsity-induced penalty term\n",
    "                for m in model.modules():\n",
    "                    if isinstance(m, nn.BatchNorm2d):\n",
    "                        m.weight.grad.data.add_(args.s*torch.sign(m.weight.data))  # L1\n",
    "\n",
    "            \n",
    "            # calculate difference for this iteration\n",
    "            optimizer.step()\n",
    "            model.cpu()\n",
    "#           # This doesn't contain BN running mean and var            \n",
    "#             new_tensors = [p.data for p in model.parameters()]\n",
    "            new_tensors = [param.data for name, param in model.state_dict().items()]\n",
    "\n",
    "            iter_diff = [(old_tensor - new_tensor)/args.num_workers for (old_tensor, new_tensor) in zip(old_tensors,new_tensors)]\n",
    "            model.cuda()\n",
    "            # print(\"passing sizes: \",sys.getsizeof(iter_diff))\n",
    "#             ps.apply_gradients.remote(iter_diff,worker_index,epoch)\n",
    "            ps.apply_gradients_with_running_bn.remote(iter_diff,worker_index,epoch)\n",
    "#             else:\n",
    "#                 old_tensors_non_bns = copy.deepcopy([param.data for name,param in model.named_parameters() if 'bn' not in name])\n",
    "#                 optimizer.step()\n",
    "#                 wk_non_bns = [param.data for name,param in model.named_parameters() if 'bn' not in name]\n",
    "#                 iter_diff_non_bns = [(old_tensor_non_bns - new_tensor_non_bns)/args.num_workers for (old_tensor_non_bns, new_tensor_non_bns) in zip(old_tensors_non_bns,wk_non_bns)]\n",
    "#                 ps.apply_gradients_non_bns.remote(iter_diff_non_bns,worker_index,epoch)\n",
    "        \n",
    "\n",
    "                \n",
    "            \n",
    "#             if worker_index == 0:\n",
    "# #                 print(worker_index, \"passing all params\")\n",
    "#                 # calculate difference for this iteration\n",
    "#                 old_tensors = copy.deepcopy([p.data for p in model.parameters()])    \n",
    "#                 optimizer.step()\n",
    "#                 new_tensors = [p.data for p in model.parameters()]\n",
    "#                 iter_diff = [(old_tensor - new_tensor)/args.num_workers for (old_tensor, new_tensor) in zip(old_tensors,new_tensors)]\n",
    "#                 # print(\"passing sizes: \",sys.getsizeof(iter_diff))\n",
    "#                 ps.apply_gradients.remote(iter_diff,worker_index,epoch)\n",
    "#             else:\n",
    "# #                 print(worker_index, \"passing non bn params\")\n",
    "#                 #calculate only non-bn parameters difference \n",
    "#                 old_tensors = copy.deepcopy([param.data for name,param in model.named_parameters() if 'bn' not in name])\n",
    "#                 optimizer.step()\n",
    "#                 new_tensors = [param.data for name,param in model.named_parameters() if 'bn' not in name]\n",
    "#                 iter_diff = [(old_tensor - new_tensor)/args.num_workers for (old_tensor, new_tensor) in zip(old_tensors,new_tensors)]\n",
    "#                 # print(\"passing sizes: \",sys.getsizeof(iter_diff))\n",
    "#                 ps.apply_gradients.remote(iter_diff,worker_index,epoch)\n",
    "\n",
    "#             # calculate bns and non_bns parameters difference\n",
    "#             optimizer.step()\n",
    "#             model.cpu()\n",
    "#             new_tensors_non_bns = [param.data for name,param in model.named_parameters() if 'bn' not in name]\n",
    "#             new_tensors_bns = [param.data for name,param in model.named_parameters() if 'bn' in name]\n",
    "#             model.cuda()\n",
    "#             iter_diff_non_bns = [(old_tensor_non_bns - new_tensor_non_bns)/args.num_workers for (old_tensor_non_bns, new_tensor_non_bns) in zip(old_tensors_non_bns,new_tensors_non_bns)]\n",
    "#             iter_diff_bns = [(old_tensor_bns - new_tensor_bns)/args.num_workers for (old_tensor_bns, new_tensor_bns) in zip(old_tensors_bns,new_tensors_bns)]\n",
    "#             # print(\"passing sizes: \",sys.getsizeof(iter_diff))\n",
    "#             ps.apply_gradients_non_bns.remote(iter_diff_non_bns,worker_index,epoch)\n",
    "#             print(worker_index, \"pushed non bns to ps and is going to push bns to ps\")\n",
    "#             ps.apply_gradients_partical_bns.remote(iter_diff_bns,worker_index,epoch)\n",
    "#             print(worker_index, \"pushed bns to ps\")\n",
    "            \n",
    "            \n",
    "#             # aggregate and sync bn parameters    \n",
    "#             if sync_bns_flag:\n",
    "#                 print(\"SYNC BNS: worker #\",worker_index,\" is checking to pull bns from ps \")\n",
    "#                 if ray.get(ps.get_bns_ready.remote()):\n",
    "#                     print(\"SYNC BNS: worker #\",worker_index,\" is pulling bns from ps \")\n",
    "#                     ps_wei = ray.get(ps.pull_weights.remote())\n",
    "#                     model.load_state_dict(ps_wei)\n",
    "#                     sync_bns_flag = False\n",
    "#             if local_step % args.sync_bns == 0:\n",
    "#                 sync_bns_flag = True\n",
    "#                 model.cpu()\n",
    "#                 if args.debug: print(\"SYNC BNS: goint to aggregate bns\")\n",
    "#                 wk_bns = [param.data for name,param in model.named_parameters() if 'bn' in name]\n",
    "#                 bns_sync = ray.get(ps.aggregate_bns.remote(wk_bns,worker_index))\n",
    "#                 print(\"SYNC BNS: bns of worker #\",worker_index,\" have been pushed\")\n",
    "                \n",
    "#                 if any(bns_sync) == False: # when all workers have pushed their own bns parameters to ps\n",
    "#                     print(\"SYNC BNS: worker #\",worker_index,\" is last worker pushed its bns\")\n",
    "#                     ps_wei = ray.get(ps.pull_weights.remote())\n",
    "#                     model.load_state_dict(ps_wei)\n",
    "#                     sync_bns_flag = False\n",
    "#                 if args.cuda: model.cuda()\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "#             if local_step in [5500,7000]:\n",
    "#                 for param_group in optimizer.param_groups:\n",
    "#                     print(\"previous lr: \",param_group['lr'])\n",
    "#                     param_group['lr'] *= 0.1\n",
    "#                     print(\"new lr: \",param_group['lr'])\n",
    "                \n",
    "            local_step += 1\n",
    "\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('The {} worker, Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "                worker_index, epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "                \n",
    "                for name,param in model.named_parameters():\n",
    "                    wk_writer.add_histogram(name, param, local_step)\n",
    "\n",
    "                wk_writer.add_scalar(\"Loss/worker_train\",loss,local_step)\n",
    "                wk_writer.add_scalar(\"Accuracy/worker_train\",batch_correct.float()/len(data),local_step)\n",
    "                \n",
    "        print(\"The {} worker finished its {} epoch with loss: {} and accuracy: {}\".format(\n",
    "            worker_index,\n",
    "            epoch,\n",
    "            avg_loss / float(len(train_loader.dataset)),\n",
    "            train_correct.float() / float(len(train_loader.dataset))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Distributed SSP CIFAR-10 Restnet train with network slimming')\n",
    "parser.add_argument('--ray-master',type=str,default='127.0.0.1')\n",
    "parser.add_argument('--redis-port',type=str,default='6379')\n",
    "parser.add_argument('--batch-size',type=int,default=64)\n",
    "parser.add_argument('--test-batch-size', type=int, default=64)\n",
    "parser.add_argument('--epochs', type=int, default=3)\n",
    "parser.add_argument('--start-epoch', default=0, type=int)\n",
    "parser.add_argument('--lr', type=float, default=0.1)\n",
    "parser.add_argument('--momentum', type=float, default=0.9)\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float)\n",
    "parser.add_argument('--resume', default=None, type=str) \n",
    "parser.add_argument('--refine', default=None, type=str) \n",
    "parser.add_argument('--no-cuda', action='store_true', default=False)\n",
    "parser.add_argument('--save', default='./logs', type=str)\n",
    "parser.add_argument('--depth', default=164, type=int)\n",
    "parser.add_argument('--tb-path', default='./logs', type=str)\n",
    "parser.add_argument('--log-interval', type=int, default=100)\n",
    "parser.add_argument('--num-workers',type=int,default=1)\n",
    "parser.add_argument('--stalness-limit',type=int,default=5)\n",
    "parser.add_argument('--debug',action='store_true',default=False)\n",
    "parser.add_argument('--sync-bns',type=int, default=194)\n",
    "parser.add_argument('--sparsity-regularization', '-sr', dest='sr', action='store_true',\n",
    "                    help='train with channel sparsity regularization')\n",
    "parser.add_argument('--s', type=float, default=0.0001,\n",
    "                    help='scale sparse rate (default: 0.0001)')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=['--num-workers=3','--tb-path=/userhome/34/gyu/logs_sr/3wk_p1',\n",
    "                               '--save=/userhome/34/gyu/logs_sr/3wk_p1',\n",
    "                               '-sr','--s=0.00001'])\n",
    "\n",
    "# '--resume=/userhome/34/gyu/logs_sr/checkpoint.pth.tar'\n",
    "# '--tb-path=logs_no_bns','--save=logs_no_bns'\n",
    "# '-sr','--s=0.00001'\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.21.5.175',\n",
       " 'redis_address': '10.21.5.175:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2019-12-17_17-29-07_147626_22517/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-12-17_17-29-07_147626_22517/sockets/raylet',\n",
       " 'webui_url': 'http://10.21.5.175:8080/?token=306ea1f13ed1c340d1d96360ba7a1b58eaab8cc975abe68e',\n",
       " 'session_dir': '/tmp/ray/session_2019-12-17_17-29-07_147626_22517'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address=args.ray_master+':'+args.redis_port)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "test_loader = generate_test_loader(args.test_batch_size)\n",
    "train_loaders = [generate_train_loader(args.batch_size,kwargs) for _ in range(args.num_workers)]\n",
    "\n",
    "resume_from_ckpt = args.resume if (args.resume and os.path.isfile(args.resume)) else None\n",
    "\n",
    "ps = ParameterServer.remote(args,test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=32752, ip=10.21.5.176)\u001b[0m worker # 0  is online\n",
      "\u001b[2m\u001b[36m(pid=32752, ip=10.21.5.176)\u001b[0m The 0 worker, Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.331258\n",
      "\u001b[2m\u001b[36m(pid=22641)\u001b[0m worker # 1  is online\n"
     ]
    }
   ],
   "source": [
    "worker_tasks = [worker_task.remote(args,ps,idx,train_loaders[idx]) for idx in range(args.num_workers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\u001b[2m\u001b[36m(pid=22641)\u001b[0m The 1 worker, Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.304541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-17 21:36:00,730\tWARNING worker.py:1779 -- The actor or task with ID 13eef3fd50e5ffffffff06000000 is pending and cannot currently be scheduled. It requires {GPU: 1.000000}, {CPU: 1.000000} for execution and {GPU: 1.000000}, {CPU: 1.000000} for placement, but this node only has remaining {CPU: 8.000000}, {memory: 30.371094 GiB}, {object_store_memory: 8.984375 GiB}. In total there are 1 pending tasks and 0 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster.\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ray.get(ps.get_stalness.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps.evaluate.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_loader = generate_test_loader(64)\n",
    "local_train_loader = generate_train_loader(64,{'num_workers': 1, 'pin_memory': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_writer = SummaryWriter()\n",
    "\n",
    "local_test_model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=164)\n",
    "checkpoint = torch.load('/userhome/34/gyu/tmp/prune_40/ssp_refine_1wk/checkpoint.pth.tar')\n",
    "local_test_model.load_state_dict(checkpoint['state_dict'])\n",
    "local_test_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pruned model\n",
    "local_test_loader = generate_test_loader(64)\n",
    "local_train_loader = generate_train_loader(64,{'num_workers': 1, 'pin_memory': True})\n",
    "\n",
    "test_writer = SummaryWriter()\n",
    "\n",
    "\n",
    "checkpoint = torch.load(args.refine)\n",
    "local_test_model = models.__dict__['resnet'](dataset='cifar10', depth=args.depth, cfg=checkpoint['cfg'])\n",
    "\n",
    "checkpoint = torch.load('/userhome/34/gyu/tmp/prune_40/ssp_refine_1wk_runningbn/checkpoint.pth.tar')\n",
    "local_test_model.load_state_dict(checkpoint['state_dict'])\n",
    "local_test_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(local_test_model, input_size=(3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "state = local_test_model.state_dict()\n",
    "for idx, p in enumerate(state):\n",
    "    data.append(state[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0][0][0][0] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=[]\n",
    "state2 = local_test_model.state_dict()\n",
    "for idx, p in enumerate(state2):\n",
    "    data2.append(state2[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state1 = local_test_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state1['layer1.0.bn1.running_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state1['layer1.0.bn1.running_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state1['layer1.0.bn1.weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state1['layer1.0.bn1.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_model = ray.get(ps.get_model.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataloader):\n",
    "    local_test_model = model\n",
    "    local_test_loader = test_dataloader\n",
    "    # local_test_model.train()\n",
    "    local_test_model.eval()\n",
    "    # test dataset loader \n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    batch_count = 0.\n",
    "    for data, target in local_test_loader:\n",
    "        data,target = data.cuda(),target.cuda()\n",
    "        batch_count += 1\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = local_test_model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).data # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        batch_correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "        correct += batch_correct\n",
    "#         if batch_count % 100  == 0:\n",
    "#             print(\"        with model.eval(), batch num: \",batch_count, \" with correct: \",int(batch_correct.data), \" / \",len(data))\n",
    "\n",
    "    test_loss /= len(local_test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.6f})\\n'.format(\n",
    "        test_loss, correct, len(local_test_loader.dataset),\n",
    "        correct / float(len(local_test_loader.dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_model.eval()\n",
    "local_test_model.cuda()\n",
    "test_model(local_test_model,local_test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经过一个epoch 的 test set\n",
    "state2 = local_test_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state2['layer1.0.bn1.running_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state2['layer1.0.bn1.running_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state2['layer1.0.bn1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state2['layer1.0.bn1.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bn层的4个参数都没有变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset loader, but set model.eval(), acc=11% for one epoch \n",
    "# local_test_model.eval()\n",
    "local_test_model.train()\n",
    "# train dataset loader\n",
    "\n",
    "test_loss = 0.\n",
    "correct = 0.\n",
    "train_batch_count = 0.\n",
    "num_batch = 0\n",
    "for data, target in local_train_loader:\n",
    "#     if train_batch_count % 30 == 0:\n",
    "#         print(train_batch_count)\n",
    "#         local_test_model.eval()\n",
    "#         test_model(local_test_model,local_test_loader)\n",
    "        \n",
    "    if train_batch_count==150:\n",
    "        break\n",
    "        \n",
    "    num_batch += 1   \n",
    "    local_test_model.train()\n",
    "    data,target = data.cuda(),target.cuda()\n",
    "    train_batch_count += 1\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = local_test_model(data)\n",
    "    test_loss += F.cross_entropy(output, target, size_average=False).data # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    batch_correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "    correct += batch_correct\n",
    "    \n",
    "    for name,param in local_test_model.named_parameters():\n",
    "        test_writer.add_histogram(name, param, num_batch)\n",
    "\n",
    "    \n",
    "#     if train_batch_count % 100  == 0:\n",
    "#         print(\"With model.train(), batch num: \",train_batch_count, \" , with correct: \",int(batch_correct.data), \" / \", len(data))\n",
    "\n",
    "test_loss /= len(local_train_loader.dataset)\n",
    "print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.6f})\\n'.format(\n",
    "    test_loss, correct, len(local_train_loader.dataset),\n",
    "    correct / float(len(local_train_loader.dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state3 = local_test_model.state_dict()\n",
    "print(state3['layer1.0.bn1.running_mean'])\n",
    "print(state3['layer1.0.bn1.running_var'])\n",
    "print(state3['layer1.0.bn1.weight'])\n",
    "print(state3['layer1.0.bn1.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_name = []\n",
    "bn_li = []\n",
    "for m in local_test_model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        bn_name.append(m.name)\n",
    "        bn_li.append(m.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'state_dict':local_test_model.state_dict(),\n",
    "}\n",
    "torch.save(state,'/userhome/34/gyu/tmp/checkpoint_tmp.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_model2\n",
    "test_model(local_test_model2,local_test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_params(model):\n",
    "    bns = {}\n",
    "    non_bns = {}\n",
    "    param_count = 0.\n",
    "    bn_param_count = 0.\n",
    "    for name,param in model.named_parameters():\n",
    "        param_count += len(param)\n",
    "        if 'bn' in name:\n",
    "            bns[name] = param\n",
    "            bn_param_count += len(param)\n",
    "        else:\n",
    "            non_bns[name] = param\n",
    "    print(\"bn params occupies: \",bn_param_count/param_count)\n",
    "    return bns,non_bns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_params(local_test_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_bns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = ray.get(ps.pull_weights.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_bn={}\n",
    "for ele in state_dict:\n",
    "    if 'bn' not in ele:\n",
    "        non_bn[ele]=state_dict[ele]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_wei = ray.get(ps.pull_weights.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_wei[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _to_remove_resnet.models as tmpmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res56 = tmpmodels.__dict__[\"resnet\"](dataset=\"cifar10\",depth=56)\n",
    "res56.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(res56, input_size=(3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "wide_50 = torch.hub.load('pytorch/vision:v0.4.2', 'wide_resnet50_2', pretrained=True)\n",
    "wide_50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(wide_50, input_size=(3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext50 = torch.hub.load('pytorch/vision:v0.4.2', 'resnext50_32x4d', pretrained=True)\n",
    "resnext50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(resnext50, input_size=(3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
