{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# pytorch optimizer 让动量参与计算，以及手动修改lr\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "import resnet.models as models\n",
    "import random,time\n",
    "from time import sleep\n",
    "import copy \n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from filelock import FileLock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_loader(batch_size,kwargs):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=True, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Pad(4),\n",
    "            transforms.RandomCrop(32),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    return train_loader\n",
    "\n",
    "def generate_test_loader(test_batch_size):\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])),batch_size=test_batch_size, shuffle=True)\n",
    "    return test_loader\n",
    "\n",
    "@ray.remote\n",
    "class ParameterServer():\n",
    "    def __init__(self,args,test_loader):\n",
    "        self.model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=args.depth)\n",
    "        self.stalness_table = [0] * args.num_workers\n",
    "        self.stalness_limit = args.stalness_limit \n",
    "        self.global_step = 0\n",
    "        self.lr = args.lr\n",
    "        self.args = args\n",
    "        self.eva_model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=args.depth)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                          lr=args.lr,\n",
    "                          momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "        self.test_loader = test_loader\n",
    "        self.model.cpu()\n",
    "        self.eva_model.cpu()\n",
    "        self.ps_writer = SummaryWriter(os.path.join(os.getcwd(),(args.tb_path+'/ps')))\n",
    "        self.save_path = args.save\n",
    "        if args.resume:\n",
    "            if os.path.isfile(args.resume):\n",
    "                print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "                checkpoint = torch.load(args.resume)\n",
    "                self.global_step = checkpoint['global_step']\n",
    "                self.model.load_state_dict(checkpoint['state_dict'])\n",
    "                self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                self.stalness_table = [self.global_step/args.num_workers] * args.num_workers\n",
    "                print(\"=> loaded checkpoint '{}' (global step: {})\".format(args.resume, checkpoint['global_step']))                \n",
    "                if 'epoch' in checkpoint: print(\"epoch: {}\".format(checkpoint['epoch']))\n",
    "            else:\n",
    "                print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    def apply_gradients(self, iter_diff, wk_idx, epoch):\n",
    "        if args.debug: print(\"applying gradients from the \",wk_idx, \" worker\")    \n",
    "            \n",
    "#         if epoch == (int)(self.args.epochs * 0.5):\n",
    "#             self.optimizer.param_groups[0]['lr'] = 0.01\n",
    "#             print(\"lr has been changed to: \",self.optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "        for idx, p in enumerate(self.model.parameters()):\n",
    "            p.data -= iter_diff[idx]\n",
    "            \n",
    "        self.stalness_table[wk_idx] += 1\n",
    "        self.global_step += 1\n",
    "        if args.debug: print(\"finished applying gradients from the \",wk_idx, \" worker\")\n",
    "        if self.global_step % 1000 == 0:\n",
    "#             print(\"global_step: \",self.global_step,\" and prepare evaluate\")\n",
    "#             self.evaluate()\n",
    "            self.save_ckpt({\n",
    "                'epoch':epoch,\n",
    "                'global_step':self.global_step,\n",
    "                'state_dict':self.model.state_dict(),\n",
    "                'optimizer':self.optimizer.state_dict()\n",
    "            },filepath=os.path.join(os.getcwd(),self.save_path))\n",
    "            \n",
    "        \n",
    "    def pull_weights(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def get_optim(self):\n",
    "        return self.optimizer\n",
    "    \n",
    "    def pull_optimizer_state(self):\n",
    "        return self.optimizer.state_dict()\n",
    "\n",
    "    def check_stalness(self,wk_idx):\n",
    "        min_iter = min(self.stalness_table)\n",
    "        return self.stalness_table[wk_idx] - min_iter < self.stalness_limit\n",
    "        \n",
    "    def get_stalness(self):\n",
    "        return min(self.stalness_table)\n",
    "    \n",
    "    def get_stalness_table(self):\n",
    "        return self.stalness_table\n",
    "    \n",
    "    def get_global_step(self):\n",
    "        return self.global_step\n",
    "    \n",
    "    def save_ckpt(self,state,filepath):\n",
    "        torch.save(state,os.path.join(filepath,'checkpoint.pth.tar'))\n",
    "        \n",
    "    def evaluate(self):\n",
    "        print(\"going to evaluate\")\n",
    "        test_loss = 0.\n",
    "        correct = 0.\n",
    "        print(\"pulled weights\")\n",
    "        self.eva_model.load_state_dict(copy.deepcopy(self.model.state_dict()))\n",
    "        print(\"loaded weights\")\n",
    "        print(\"length of the test_loader dataset is : \",len(self.test_loader.dataset))\n",
    "        self.eva_model.eval()\n",
    "        count = 0\n",
    "        for data,target in self.test_loader:\n",
    "            count += 1\n",
    "            if count % 20 == 0: print(\"in eval, the batch is: \",count)\n",
    "            data, target = Variable(data,volatile=True),Variable(target)\n",
    "            output = self.eva_model(data)\n",
    "            batch_loss = F.cross_entropy(output, target, size_average=False).data\n",
    "            test_loss += batch_loss\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        len_testset = len(self.test_loader.dataset)\n",
    "        test_loss /= len_testset \n",
    "        accuracy = correct / len_testset\n",
    "        # log \n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len_testset,accuracy))\n",
    "\n",
    "        self.ps_writer.add_scalar('Accuracy/eval', accuracy, self.global_step)\n",
    "        self.ps_writer.add_scalar('Loss/eval',test_loss , self.global_step)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def worker_task(args,ps,worker_index, train_loader):\n",
    "    # Initialize the model.\n",
    "#     if args.debug: print(worker_index, \" worker is going to sleep \",worker_index*5000)\n",
    "#     time.sleep(worker_index * 5000)\n",
    "    \n",
    "    model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=args.depth)\n",
    "    local_step = 0\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=args.lr,\n",
    "                          momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "    if args.cuda:\n",
    "        starttime = datetime.datetime.now()\n",
    "        model.cuda()\n",
    "        endtime = datetime.datetime.now()\n",
    "        time_cost = (endtime - starttime).seconds\n",
    "        if args.debug: print(\"move model to gpu takes: \", time_cost, \"seconds\")\n",
    "    if args.resume:\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        local_step = checkpoint['global_step'] / args.num_workers\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        if 'epoch' in checkpoint:\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "\n",
    "    wk_writer = SummaryWriter(os.path.join(os.getcwd(),args.tb_path,('wk_'+str(worker_index))))\n",
    "    \n",
    "    for epoch in range(args.start_epoch,args.epochs):\n",
    "        avg_loss = 0.\n",
    "        train_acc = 0.\n",
    "        for batch_idx,(data,target) in enumerate(train_loader):\n",
    "            if args.cuda:\n",
    "                starttime = datetime.datetime.now()\n",
    "                data,target = data.cuda(),target.cuda()\n",
    "                mid = datetime.datetime.now()\n",
    "                if args.debug: print(\"move data to gpu takes: \", (mid - starttime).seconds, \"seconds\")\n",
    "                model.cuda()\n",
    "                endtime = datetime.datetime.now()\n",
    "                time_cost = (endtime - starttime).seconds\n",
    "                if args.debug: print(\"move model to gpu takes: \", time_cost, \"seconds\")\n",
    "                \n",
    "            while(local_step - ray.get(ps.get_stalness.remote()) > args.stalness_limit):\n",
    "                print(worker_index,\" works too fast\")\n",
    "                sleep(1)\n",
    "            # Get the current weights from the parameter server.\n",
    "            if args.debug: print(\"the \",worker_index,\" pulls wei from ps.\")\n",
    "            init_wei = ray.get(ps.pull_weights.remote())\n",
    "            model.load_state_dict(init_wei)\n",
    "            if args.debug: print(\"the \",worker_index,\" loaded the latest wei from ps.\")\n",
    "            # Compute an update and push it to the parameter server.        \n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            if args.debug: print(worker_index,' is generating output')\n",
    "            output = model(data)\n",
    "            if args.debug: print(worker_index,' generated output done and going to calculate loss')\n",
    "            loss = F.cross_entropy(output,target)\n",
    "            avg_loss += loss\n",
    "            pred = output.data.max(1,keepdim=True)[1]\n",
    "            batch_acc = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            train_acc += batch_acc\n",
    "            if args.debug: print(worker_index,' calculated loss and going to bp')\n",
    "            loss.backward()\n",
    "            if args.debug: print(worker_index,' bp done')\n",
    "            starttime = datetime.datetime.now()\n",
    "            model.cpu()\n",
    "            endtime = datetime.datetime.now()\n",
    "            time_cost = (endtime - starttime).seconds\n",
    "            if args.debug: print(\"move model to cpu takes: \", time_cost, \"seconds\")\n",
    "            old_tensors = copy.deepcopy([p.data for p in model.parameters()])    \n",
    "            optimizer.step()\n",
    "            new_tensors = [p.data for p in model.parameters()]\n",
    "            local_step += 1\n",
    "            iter_diff = [old_tensor - new_tensor for (old_tensor, new_tensor) in zip(old_tensors,new_tensors)]\n",
    "            ps.apply_gradients.remote(iter_diff,worker_index,epoch)\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('The {} worker, Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "                worker_index, epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "                wk_writer.add_scalar(\"Loss/worker_train\",loss,local_step)\n",
    "                wk_writer.add_scalar(\"Accuracy/worker_train\",batch_acc,local_step)\n",
    "        print(\"The {} worker finished its {} epoch with loss: {} and accuracy: {}\".format(\n",
    "            worker_index,\n",
    "            epoch,\n",
    "            avg_loss / len(train_loader),\n",
    "            train_acc / float(len(train_loader)\n",
    "        )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Distributed SSP CIFAR-10 Restnet train with network slimming')\n",
    "parser.add_argument('--ray-master',type=str,default='127.0.0.1')\n",
    "parser.add_argument('--redis-port',type=str,default='6379')\n",
    "parser.add_argument('--batch-size',type=int,default=64)\n",
    "parser.add_argument('--test-batch-size', type=int, default=64)\n",
    "parser.add_argument('--epochs', type=int, default=160)\n",
    "parser.add_argument('--start-epoch', default=0, type=int)\n",
    "parser.add_argument('--lr', type=float, default=0.1)\n",
    "parser.add_argument('--momentum', type=float, default=0.9)\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float)\n",
    "parser.add_argument('--resume', default=None, type=str) \n",
    "parser.add_argument('--no-cuda', action='store_true', default=False)\n",
    "parser.add_argument('--save', default='./logs', type=str)\n",
    "parser.add_argument('--depth', default=164, type=int)\n",
    "parser.add_argument('--tb-path', default='./logs', type=str)\n",
    "parser.add_argument('--log-interval', type=int, default=100)\n",
    "parser.add_argument('--num-workers',type=int,default=1)\n",
    "parser.add_argument('--stalness-limit',type=int,default=5)\n",
    "parser.add_argument('--debug',action='store_true',default=False)\n",
    "\n",
    "args = parser.parse_args(args=['--num-workers=3','--resume=/userhome/34/gyu/logs/checkpoint.pth.tar'])\n",
    "# '--resume=/userhome/34/gyu/logs/checkpoint.pth.tar',\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.21.5.171',\n",
       " 'redis_address': '10.21.5.171:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2019-11-25_15-37-23_318826_32312/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-11-25_15-37-23_318826_32312/sockets/raylet',\n",
       " 'webui_url': 'http://10.21.5.171:8080/?token=4d52497a8914e8a2b0d5eb7019ae2ed3b1d99039d5c83c00',\n",
       " 'session_dir': '/tmp/ray/session_2019-11-25_15-37-23_318826_32312'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address=args.ray_master+':'+args.redis_port)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=30727, ip=10.21.5.172)\u001b[0m => loading checkpoint '/userhome/34/gyu/logs/checkpoint.pth.tar'\n",
      "\u001b[2m\u001b[36m(pid=30727, ip=10.21.5.172)\u001b[0m => loaded checkpoint '/userhome/34/gyu/logs/checkpoint.pth.tar' (global step: 46000)\n",
      "\u001b[2m\u001b[36m(pid=30727, ip=10.21.5.172)\u001b[0m epoch: 16\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "test_loader = generate_test_loader(args.test_batch_size)\n",
    "train_loaders = [generate_train_loader(args.batch_size,kwargs) for _ in range(args.num_workers)]\n",
    "\n",
    "resume_from_ckpt = args.resume if (args.resume and os.path.isfile(args.resume)) else None\n",
    "\n",
    "ps = ParameterServer.remote(args,test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m The 0 worker, Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.132345\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m The 1 worker, Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.244741\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n"
     ]
    }
   ],
   "source": [
    "worker_tasks = [worker_task.remote(args,ps,idx,train_loaders[idx]) for idx in range(args.num_workers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m The 2 worker, Train Epoch: 16 [0/50000 (0.0%)]\tLoss: 0.082775\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m The 0 worker, Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.220189\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m The 2 worker, Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.243885\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m The 1 worker, Train Epoch: 16 [6400/50000 (12.8%)]\tLoss: 0.414694\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m The 2 worker, Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.127468\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m The 0 worker, Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.228015\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m 2  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m The 1 worker, Train Epoch: 16 [12800/50000 (25.6%)]\tLoss: 0.370515\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m 2  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m 2  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m The 0 worker, Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.199259\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m The 2 worker, Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.396888\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m The 1 worker, Train Epoch: 16 [19200/50000 (38.4%)]\tLoss: 0.100970\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m 2  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m 2  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m The 2 worker, Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.395233\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m The 0 worker, Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.112621\n",
      "\u001b[2m\u001b[36m(pid=30729, ip=10.21.5.172)\u001b[0m The 1 worker, Train Epoch: 16 [25600/50000 (51.2%)]\tLoss: 0.407403\n",
      "\u001b[2m\u001b[36m(pid=32346)\u001b[0m 2  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=17473, ip=10.21.5.173)\u001b[0m 0  works too fast\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.get(ps.get_optim.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is in  1  batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is in  2  batch\n",
      "this is in  3  batch\n",
      "this is in  4  batch\n",
      "this is in  5  batch\n",
      "this is in  6  batch\n",
      "this is in  7  batch\n",
      "this is in  8  batch\n",
      "this is in  9  batch\n",
      "this is in  10  batch\n",
      "this is in  11  batch\n",
      "this is in  12  batch\n",
      "this is in  13  batch\n",
      "this is in  14  batch\n",
      "this is in  15  batch\n",
      "this is in  16  batch\n",
      "this is in  17  batch\n",
      "this is in  18  batch\n",
      "this is in  19  batch\n",
      "this is in  20  batch\n",
      "this is in  21  batch\n",
      "this is in  22  batch\n",
      "this is in  23  batch\n",
      "this is in  24  batch\n",
      "this is in  25  batch\n",
      "this is in  26  batch\n",
      "this is in  27  batch\n",
      "this is in  28  batch\n",
      "this is in  29  batch\n",
      "this is in  30  batch\n",
      "this is in  31  batch\n",
      "this is in  32  batch\n",
      "this is in  33  batch\n",
      "this is in  34  batch\n",
      "this is in  35  batch\n",
      "this is in  36  batch\n",
      "this is in  37  batch\n",
      "this is in  38  batch\n",
      "this is in  39  batch\n",
      "this is in  40  batch\n",
      "\n",
      "Test set: Average loss: 22.0370, Accuracy: 1155/10000 (11.0%)\n",
      "\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "local_test_loader = generate_test_loader(256)\n",
    "\n",
    "# test batch size = 256 , model.train(),  acc = 85%\n",
    "# test batch size = 256 , model.eval(),  acc = 11%\n",
    "# test batch size = 64 , model.train(),  acc = 84%\n",
    "# test batch size = 64 , model.eval(),  acc = 11%\n",
    "\n",
    "local_test_model = models.__dict__[\"resnet\"](dataset=\"cifar10\",depth=args.depth)\n",
    "checkpoint = torch.load('/userhome/34/gyu/logs/checkpoint.pth.tar')\n",
    "local_test_model.load_state_dict(checkpoint['state_dict'])\n",
    "local_test_model.cuda()\n",
    "local_test_model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "batch_count = 0\n",
    "for data, target in local_test_loader:\n",
    "    data,target = data.cuda(),target.cuda()\n",
    "    batch_count += 1\n",
    "    print(\"this is in \",batch_count, \" batch\")\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = local_test_model(data)\n",
    "    test_loss += F.cross_entropy(output, target, size_average=False).data # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "test_loss /= len(local_test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "    test_loss, correct, len(local_test_loader.dataset),\n",
    "    100. * correct / len(local_test_loader.dataset)))\n",
    "print(correct / float(len(local_test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
