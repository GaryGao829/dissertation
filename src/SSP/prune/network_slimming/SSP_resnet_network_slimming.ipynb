{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2019-11-05 22:11:00,368\tWARNING worker.py:1426 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-11-05 22:11:00,373\tINFO resource_spec.py:205 -- Starting Ray with 9.28 GiB memory available for workers and up to 5.59 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.21.5.174',\n",
       " 'redis_address': '10.21.5.174:14237',\n",
       " 'object_store_address': '/tmp/ray/session_2019-11-05_22-11-00_371096_3747/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-11-05_22-11-00_371096_3747/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-11-05_22-11-00_371096_3747'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "import resnet.models as models\n",
    "import random,time\n",
    "from time import sleep\n",
    "import copy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(memory=10000000000,object_store_memory=6000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"resnet\"\n",
    "# depth = 56\n",
    "depth = 164\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda = False\n",
    "seed = 1\n",
    "save = \"./logs\"\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 64\n",
    "test_batch_size = 500\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "ckpt_ssp_resnet = \"./ckpt_ssp_resnet_slim/checkpoint.pth.tar\"\n",
    "\n",
    "lr = 0.01 # changed from 0.01 to 0.001 at eval acc 57%\n",
    "momentum=0.9\n",
    "weight_decay=5e-4 # changed from 1e-4 to 5e-4\n",
    "log_interval=100\n",
    "start_epoch = 0\n",
    "epochs=160\n",
    "\n",
    "# network slimming\n",
    "sparsity = True\n",
    "bn_lambda = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save):\n",
    "    os.makedirs(save)\n",
    "# if not os.path.exists(ckpt_ssp_resnet):\n",
    "#     os.makedirs(ckpt_ssp_resnet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"cifar10\":\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Pad(4),\n",
    "                           transforms.RandomCrop(32),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=0.2)\n",
    "# @ray.remote\n",
    "class ParameterServer():\n",
    "    def __init__(self,lr,num_workers,stalness_limit,test_loader,resume_from_ckpt=None):\n",
    "        self.lr = lr\n",
    "        self.model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "        self.stalness_table = [0] * num_workers\n",
    "        self.stalness_limit = stalness_limit \n",
    "        self.global_step = 0\n",
    "        self.eva_model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "#         self.eva_model.eval()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "        self.test_loader = test_loader\n",
    "        if cuda:\n",
    "            self.model.cuda()\n",
    "            self.eva_model.cuda()\n",
    "        # tensorboard logger\n",
    "        self.ps_writer = SummaryWriter(\"ssp_resnet_runs_decay_more/ps\")\n",
    "        \n",
    "        if resume_from_ckpt:\n",
    "            self.model.load_state_dict(torch.load(resume_from_ckpt))\n",
    "\n",
    "#     # additional subgradient descent on the sparsity-induced penalty term\n",
    "#     def updateBN(self):\n",
    "#         for m in self.model.modules():\n",
    "#             if isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.grad.data.add_(bn_lambda*torch.sign(m.weight.data))  # L1\n",
    "                \n",
    "    def apply_gradients(self, gradients, wk_idx):\n",
    "        print(\"applying gradients from the \",wk_idx, \" worker\")\n",
    "        for idx, p in enumerate(self.model.parameters()):\n",
    "            p.data -= self.lr * gradients[idx]\n",
    "        self.stalness_table[wk_idx] += 1\n",
    "        self.global_step += 1\n",
    "#         if sparsity:\n",
    "#             self.updateBN()\n",
    "        print(\"finished applying gradients from the \",wk_idx, \" worker\")\n",
    "        if self.global_step % 50 == 0:\n",
    "            print(\"global_step: \",self.global_step,\" and prepare evaluate\")\n",
    "            self.evaluate()\n",
    "        \n",
    "    def pull_weights(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def check_stalness(self,wk_idx):\n",
    "        min_iter = min(self.stalness_table)\n",
    "        return self.stalness_table[wk_idx] - min_iter < self.stalness_limit\n",
    "        \n",
    "    def get_stalness(self):\n",
    "        return min(self.stalness_table)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        print(\"going to evaluate\")\n",
    "        test_loss = 0.\n",
    "        correct = 0.\n",
    "#         print(\"pulled weights\")\n",
    "        self.eva_model.load_state_dict(copy.deepcopy(self.model.state_dict()))\n",
    "#         print(\"loaded weights\")\n",
    "#         print(\"length of the test_loader dataset is : \",len(test_loader.dataset))\n",
    "        batch = iter(test_loader)\n",
    "        data,target = next(batch)\n",
    "        if cuda: \n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        data,target = Variable(data,volatile=True),Variable(target)\n",
    "        output = self.eva_model(data)\n",
    "        test_loss = F.cross_entropy(output,target,size_average=True)\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        #log tensorboard\n",
    "        self.ps_writer.add_scalar('Accuracy/eval', (100.0 * correct) / len(data), self.global_step)\n",
    "        self.ps_writer.add_scalar('Loss/eval',test_loss , self.global_step)\n",
    "        \n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            test_loss, \n",
    "            correct, \n",
    "            len(data),\n",
    "            100. * correct / len(data)))\n",
    "        \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_stalness_table(self):\n",
    "        return self.stalness_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=0.2)\n",
    "# @ray.remote\n",
    "def worker_task(ps,worker_index,stale_limit, train_loader,lr,momentum,weight_decay,bn_lambda,batch_size=50):\n",
    "    # Initialize the model.\n",
    "    model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "    local_step = 0\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    wk_writer = SummaryWriter(\"ssp_resnet_runs_decay_more/wk_\"+str(worker_index))\n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        while(local_step - ray.get(ps.get_stalness.remote()) > stale_limit):\n",
    "            print(worker_index,\" works too fast\")\n",
    "            sleep(1)\n",
    "            \n",
    "        # Get the current weights from the parameter server.\n",
    "#         print(\"the \",worker_index,\" pulls wei from ps.\")\n",
    "        init_wei = ray.get(ps.pull_weights.remote())\n",
    "        model.load_state_dict(init_wei)\n",
    "#         print(\"the \",worker_index,\" loaded the latest wei from ps.\")\n",
    "\n",
    "        # Compute an update and push it to the parameter server.        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(data),target)\n",
    "        loss.backward()\n",
    "        \n",
    "        # slimming \n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.grad.data.add_(bn_lambda*torch.sign(m.weight.data))  # L1\n",
    "                \n",
    "        grad = [p.grad for p in model.parameters()]\n",
    "        local_step += 1\n",
    "        ps.apply_gradients.remote(grad,worker_index)\n",
    "        optimizer.step()\n",
    "        wk_writer.add_scalar(\"Loss/worker_train\",loss,local_step)\n",
    "        print(\"the \",worker_index,\" has finished its \",local_step,\" update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-05 22:11:12,246\tWARNING worker.py:1779 -- Warning: The actor ParameterServer has size 30746018 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "num_worker = 4\n",
    "stalness_table = [0] * num_worker\n",
    "stalness_limit = 4\n",
    "\n",
    "# ps = ParameterServer.remote(lr,num_worker,stalness_limit,test_loader,ckpt_ssp_resnet)\n",
    "ps = ParameterServer.remote(lr,num_worker,stalness_limit,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3795)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3793)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m   _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m   _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m   _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m   _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\u001b[2m\u001b[36m(pid=3794)\u001b[0m   np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  1  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  2  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  1  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  3  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  2  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  1  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  4  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n"
     ]
    }
   ],
   "source": [
    "worker_tasks = [worker_task.remote(ps,i,stalness_limit,train_loader,lr,momentum,weight_decay,bn_lambda) \n",
    "                for i in range(num_worker)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stalness = ray.get(ps.get_stalness_table.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  6  update\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  5  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  2  update\n"
     ]
    }
   ],
   "source": [
    "stalness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ckpt at: \n",
      "2019-11-05 22:13:28.691633\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  6  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  5  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  7  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  3  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  7  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  6  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  8  update\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  4  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  7  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  8  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  5  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  9  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  8  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  9  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  6  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  10  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  9  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  10  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  7  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  11  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  10  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  11  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  8  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  12  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  11  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  12  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  9  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  13  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  12  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  13  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  10  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  14  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m global_step:  50  and prepare evaluate\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m going to evaluate\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  14  update\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  13  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ray/workers/default_worker.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   args = parser.parse_args()\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  11  update\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  15  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m   warnings.warn(warning.format(ret))\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m Test set: Average loss: 7.9290, Accuracy: 44/500 (8.0%)\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  15  update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  12  update\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  14  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  16  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  16  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  17  update\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  13  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  15  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  17  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  14  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  16  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  18  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  18  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  15  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  17  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  19  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  19  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  18  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  20  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  16  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  20  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  19  update\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  21  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  17  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  21  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  20  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  22  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  18  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  22  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  21  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  19  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  23  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  23  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  22  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  20  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  24  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  24  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  23  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  21  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  25  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  25  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  24  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  22  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  26  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  26  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  25  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m global_step:  100  and prepare evaluate\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m going to evaluate\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  23  update\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  27  update\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  27  update\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  26  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m Test set: Average loss: 4.6201, Accuracy: 73/500 (14.0%)\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  27  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  24  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  28  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  28  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  28  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  25  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  29  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  29  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  29  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  26  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  30  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  30  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  30  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  27  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  31  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  31  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  31  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  32  update\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  28  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  32  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  33  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m 1  works too fast\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  29  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  32  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  33  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  30  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  33  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  34  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  34  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  31  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  34  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  35  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  35  update\n",
      "saved ckpt at: \n",
      "2019-11-05 22:23:29.109499\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  32  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  35  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  36  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  36  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  33  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  36  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  37  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  37  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  3  worker\n",
      "\u001b[2m\u001b[36m(pid=3787)\u001b[0m the  3  has finished its  34  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  2  worker\n",
      "\u001b[2m\u001b[36m(pid=3786)\u001b[0m the  2  has finished its  37  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3784)\u001b[0m the  1  has finished its  38  update\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  1  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3785)\u001b[0m finished applying gradients from the  0  worker\n",
      "\u001b[2m\u001b[36m(pid=3788)\u001b[0m the  0  has finished its  38  update\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-05 22:24:31,353\tWARNING worker.py:1779 -- The log monitor on node gpu-comp-204 failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ray/log_monitor.py\", line 202, in check_log_files_and_publish_updates\n",
      "    next_line = file_info.file_handle.readline()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ray/log_monitor.py\", line 301, in <module>\n",
      "    log_monitor.run()\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ray/log_monitor.py\", line 252, in run\n",
      "    anything_published = self.check_log_files_and_publish_updates()\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ray/log_monitor.py\", line 215, in check_log_files_and_publish_updates\n",
      "    file_info.full_path,\n",
      "AttributeError: 'LogFileInfo' object has no attribute 'full_path'\n",
      "\n",
      "2019-11-05 22:24:33,568\tWARNING worker.py:1779 -- A worker died or was killed while executing task 6f62e931e1b87d58f41501000000.\n",
      "2019-11-05 22:24:38,582\tERROR worker.py:1719 -- Possible unhandled error from worker: \u001b[36mray_worker\u001b[39m (pid=3787, host=gpu-comp-204)\n",
      "  File \"<ipython-input-6-660cdb44b037>\", line 17, in worker_task\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\n",
      "2019-11-05 22:24:40,586\tERROR worker.py:1719 -- Possible unhandled error from worker: \u001b[36mray_worker\u001b[39m (pid=3786, host=gpu-comp-204)\n",
      "  File \"<ipython-input-6-660cdb44b037>\", line 17, in worker_task\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\n",
      "2019-11-05 22:24:41,588\tERROR worker.py:1719 -- Possible unhandled error from worker: \u001b[36mray_worker\u001b[39m (pid=3784, host=gpu-comp-204)\n",
      "  File \"<ipython-input-6-660cdb44b037>\", line 17, in worker_task\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\n",
      "2019-11-05 22:24:43,591\tERROR worker.py:1719 -- Possible unhandled error from worker: \u001b[36mray_worker\u001b[39m (pid=3788, host=gpu-comp-204)\n",
      "  File \"<ipython-input-6-660cdb44b037>\", line 17, in worker_task\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\n"
     ]
    },
    {
     "ename": "RayActorError",
     "evalue": "The actor died unexpectedly before finishing this task.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0093532ed9ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mwei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpull_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwei\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mckpt_ssp_resnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved ckpt at: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_ids)\u001b[0m\n\u001b[1;32m   2347\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnreconstructableError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2349\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         \u001b[0;31m# Run post processors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayActorError\u001b[0m: The actor died unexpectedly before finishing this task."
     ]
    }
   ],
   "source": [
    "def save_checkpoint(state, is_best, filepath):\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(os.path.join(filepath, 'checkpoint.pth.tar'), os.path.join(filepath, 'model_best.pth.tar'))\n",
    "\n",
    "import datetime\n",
    "\n",
    "while True:\n",
    "    wei = ray.get(ps.pull_weights.remote())\n",
    "    save_checkpoint(wei,False,ckpt_ssp_resnet)\n",
    "    print(\"saved ckpt at: \", )\n",
    "    print(datetime.datetime.now())\n",
    "    time.sleep(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
