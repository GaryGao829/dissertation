{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-31 22:17:52,786\tWARNING worker.py:1426 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-10-31 22:17:52,795\tINFO resource_spec.py:205 -- Starting Ray with 4.64 GiB memory available for workers and up to 2.79 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.21.5.177',\n",
       " 'redis_address': '10.21.5.177:28261',\n",
       " 'object_store_address': '/tmp/ray/session_2019-10-31_22-17-52_788610_13636/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-10-31_22-17-52_788610_13636/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-10-31_22-17-52_788610_13636'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "import resnet.models as models\n",
    "import random,time\n",
    "from time import sleep\n",
    "import copy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(memory=5000000000,object_store_memory=3000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"resnet\"\n",
    "depth = 56\n",
    "# cuda = torch.cuda.is_available()\n",
    "cuda = False\n",
    "seed = 1\n",
    "save = \"./logs\"\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 1000\n",
    "test_batch_size = 1000\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "lr = 0.1\n",
    "momentum=0.9\n",
    "weight_decay=1e-4\n",
    "log_interval=100\n",
    "start_epoch = 0\n",
    "epochs=160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save):\n",
    "    os.makedirs(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"cifar10\":\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Pad(4),\n",
    "                           transforms.RandomCrop(32),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=1)\n",
    "# @ray.remote\n",
    "class ParameterServer():\n",
    "    def __init__(self,lr,num_workers,stalness_limit,test_loader):\n",
    "        self.lr = lr\n",
    "        self.model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "        self.stalness_table = [0] * num_workers\n",
    "        self.stalness_limit = stalness_limit \n",
    "        self.global_step = 0\n",
    "        self.eva_model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "    def apply_gradients(self, gradients, wk_idx):\n",
    "        for p in self.model.parameters():\n",
    "            p.data -= self.lr * p.grad.data\n",
    "        self.stalness_table[wk_idx] += 1\n",
    "        self.global_step += 1\n",
    "        if self.global_step % 100 == 0:\n",
    "            print(\"global_step: \",self.global_step,\" and prepare evaluate\")\n",
    "            self.evaluate()\n",
    "        \n",
    "    def pull_weights(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def check_stalness(self,wk_idx):\n",
    "        min_iter = min(self.stalness_table)\n",
    "        return self.stalness_table[wk_idx] - min_iter < self.stalness_limit\n",
    "        \n",
    "    def get_stalness(self):\n",
    "        return min(self.stalness_table)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.eva_model.eval()\n",
    "        test_loss = 0.\n",
    "        correct = 0.\n",
    "        cur_wei = self.pull_weights()\n",
    "        self.eva_model.load_state_dict(cur_wei)\n",
    "        for data,target in test_loader:\n",
    "            if cuda: \n",
    "                data,target = data.cuda(),target.cuda()\n",
    "            data,target = Variable(data,volatile=True),Variable(target)\n",
    "            output = self.eva_model(data)\n",
    "            test_loss += F.cross_entropy(output,target,size_average=False)\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            test_loss, \n",
    "            correct, \n",
    "            len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "        \n",
    "@ray.remote(num_cpus=1)\n",
    "# @ray.remote\n",
    "def worker_task(ps,worker_index,stale_limit, train_loader,lr,momentum,weight_decay,batch_size=50):\n",
    "    # Initialize the model.\n",
    "    model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "    local_step = 0\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        while(local_step - ray.get(ps.get_stalness.remote()) > stale_limit):\n",
    "            print(worker_index,\" works too fast\")\n",
    "            sleep(1)\n",
    "        # Get the current weights from the parameter server.\n",
    "        init_wei = ray.get(ps.pull_weights.remote())\n",
    "        model.load_state_dict(init_wei)\n",
    "        \n",
    "        # Compute an update and push it to the parameter server.        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(data),target)\n",
    "        loss.backward()\n",
    "        grad = [p.grad for p in model.parameters()]\n",
    "        local_step += 1\n",
    "        ps.apply_gradients.remote(grad,worker_index)\n",
    "        optimizer.step()\n",
    "        print(worker_index,\"has finished update\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-31 22:18:04,114\tWARNING worker.py:1779 -- Warning: The actor ParameterServer has size 30745185 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
     ]
    }
   ],
   "source": [
    "num_worker = 1\n",
    "stalness_table = [0] * num_worker\n",
    "stalness_limit = 4\n",
    "\n",
    "ps = ParameterServer.remote(0.1,num_worker,stalness_limit,test_loader)\n",
    "# worker_tasks = [worker_task.remote(ps,i,stalness_limit) for i in range(num_worker)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13674)\u001b[0m THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=51 error=38 : no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-31 22:18:23,513\tERROR worker.py:1719 -- Possible unhandled error from worker: \u001b[36mray_worker\u001b[39m (pid=13674, host=gpu-comp-207)\n",
      "  File \"<ipython-input-5-71b42fe33335>\", line 82, in worker_task\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/userhome/34/gyu/git_folder/dissertation/src/SSP/resnet/models/resnet.py\", line 119, in forward\n",
      "    x = self.layer2(x)  # 16x16\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/userhome/34/gyu/git_folder/dissertation/src/SSP/resnet/models/resnet.py\", line 44, in forward\n",
      "    residual = self.downsample(x)\n",
      "  File \"/userhome/34/gyu/git_folder/dissertation/src/SSP/resnet/models/resnet.py\", line 55, in downsample_basic_block\n",
      "    if isinstance(x.data, torch.cuda.FloatTensor):\n",
      "  File \"/userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 163, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worker_tasks = [worker_task.remote(ps,i,stalness_limit,train_loader,lr,momentum,weight_decay) \n",
    "                for i in range(num_worker)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
