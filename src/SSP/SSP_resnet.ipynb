{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-01 14:00:31,336\tWARNING worker.py:1426 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-11-01 14:00:31,345\tINFO resource_spec.py:205 -- Starting Ray with 9.28 GiB memory available for workers and up to 5.59 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.21.5.177',\n",
       " 'redis_address': '10.21.5.177:63974',\n",
       " 'object_store_address': '/tmp/ray/session_2019-11-01_14-00-31_339910_29637/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-11-01_14-00-31_339910_29637/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-11-01_14-00-31_339910_29637'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "import resnet.models as models\n",
    "import random,time\n",
    "from time import sleep\n",
    "import copy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(memory=10000000000,object_store_memory=6000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"resnet\"\n",
    "depth = 56\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda = False\n",
    "seed = 1\n",
    "save = \"./logs\"\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 64\n",
    "test_batch_size = 65\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "lr = 0.1\n",
    "momentum=0.9\n",
    "weight_decay=1e-4\n",
    "log_interval=100\n",
    "start_epoch = 0\n",
    "epochs=160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save):\n",
    "    os.makedirs(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"cifar10\":\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Pad(4),\n",
    "                           transforms.RandomCrop(32),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=0.3)\n",
    "# @ray.remote\n",
    "class ParameterServer():\n",
    "    def __init__(self,lr,num_workers,stalness_limit,test_loader):\n",
    "        self.lr = lr\n",
    "        self.model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "        self.stalness_table = [0] * num_workers\n",
    "        self.stalness_limit = stalness_limit \n",
    "        self.global_step = 0\n",
    "        self.eva_model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "        self.test_loader = test_loader\n",
    "        if cuda:\n",
    "            self.model.cuda()\n",
    "            self.eva_model.cuda()\n",
    "    def apply_gradients(self, gradients, wk_idx):\n",
    "        for idx, p in enumerate(self.model.parameters()):\n",
    "            p.data -= self.lr * gradients[idx]\n",
    "        self.stalness_table[wk_idx] += 1\n",
    "        self.global_step += 1\n",
    "        if self.global_step % 100 == 0:\n",
    "            print(\"global_step: \",self.global_step,\" and prepare evaluate\")\n",
    "            self.evaluate()\n",
    "        \n",
    "    def pull_weights(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def check_stalness(self,wk_idx):\n",
    "        min_iter = min(self.stalness_table)\n",
    "        return self.stalness_table[wk_idx] - min_iter < self.stalness_limit\n",
    "        \n",
    "    def get_stalness(self):\n",
    "        return min(self.stalness_table)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        print(\"going to evaluate\")\n",
    "        self.eva_model.eval()\n",
    "        test_loss = 0.\n",
    "        correct = 0.\n",
    "        cur_wei = self.pull_weights()\n",
    "        print(\"pulled weights\")\n",
    "        self.eva_model.load_state_dict(cur_wei)\n",
    "        print(\"loaded weights\")\n",
    "        print(\"length of the test_loader dataset is : \",len(test_loader.dataset))\n",
    "        batch = iter(test_loader)\n",
    "        data,target = next(batch)\n",
    "        if cuda: \n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        data,target = Variable(data,volatile=True),Variable(target)\n",
    "        output = self.eva_model(data)\n",
    "        test_loss = F.cross_entropy(output,target,size_average=True)\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "            test_loss, \n",
    "            correct, \n",
    "            len(data),\n",
    "            100. * correct / len(data)))\n",
    "\n",
    "\n",
    "        \n",
    "@ray.remote(num_gpus=0.3)\n",
    "# @ray.remote\n",
    "def worker_task(ps,worker_index,stale_limit, train_loader,lr,momentum,weight_decay,batch_size=50):\n",
    "    # Initialize the model.\n",
    "    model = models.__dict__[arch](dataset=dataset,depth=depth)\n",
    "    local_step = 0\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        while(local_step - ray.get(ps.get_stalness.remote()) > stale_limit):\n",
    "            print(worker_index,\" works too fast\")\n",
    "            sleep(1)\n",
    "        # Get the current weights from the parameter server.\n",
    "        init_wei = ray.get(ps.pull_weights.remote())\n",
    "        model.load_state_dict(init_wei)\n",
    "        \n",
    "        # Compute an update and push it to the parameter server.        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(data),target)\n",
    "        loss.backward()\n",
    "        grad = [p.grad for p in model.parameters()]\n",
    "        local_step += 1\n",
    "        ps.apply_gradients.remote(grad,worker_index)\n",
    "        optimizer.step()\n",
    "        print(worker_index,\"has finished update\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-01 14:00:43,197\tWARNING worker.py:1779 -- Warning: The actor ParameterServer has size 30745381 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
     ]
    }
   ],
   "source": [
    "num_worker = 2\n",
    "stalness_table = [0] * num_worker\n",
    "stalness_limit = 4\n",
    "\n",
    "ps = ParameterServer.remote(0.1,num_worker,stalness_limit,test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0  works too fast\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m global_step:  100  and prepare evaluate\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m going to evaluate\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m pulled weights\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m loaded weights\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m length of the test_loader dataset is :  10000\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/ray/workers/default_worker.py:52: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m   default=ray_constants.LOGGER_FORMAT,\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m Test set: Average loss: 280593.2500, Accuracy: 8/65 (12.0%)\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m /userhome/34/gyu/anaconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "\u001b[2m\u001b[36m(pid=29678)\u001b[0m   warnings.warn(warning.format(ret))\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29674)\u001b[0m 0 has finished update\n",
      "\u001b[2m\u001b[36m(pid=29672)\u001b[0m 1 has finished update\n"
     ]
    }
   ],
   "source": [
    "worker_tasks = [worker_task.remote(ps,i,stalness_limit,train_loader,lr,momentum,weight_decay) \n",
    "                for i in range(num_worker)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
